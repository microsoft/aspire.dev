---
title: Azure AI Foundry integration
description: This article describes the Aspire Azure AI Foundry integration features and capabilities.
---

import { Aside, Badge } from '@astrojs/starlight/components';
import InstallPackage from '@components/InstallPackage.astro';
import InstallDotNetPackage from '@components/InstallDotNetPackage.astro';
import { Image } from 'astro:assets';
import aiFoundryIcon from '@assets/icons/azure-ai-foundry-icon.png';

<Image
  src={aiFoundryIcon}
  alt="Azure AI Foundry logo"
  height={80}
  width={80}
  class:list={'float-inline-left icon'}
  data-zoom-off
/>

<Badge text="ðŸ§ª Preview" variant="note" size="large" />

[Azure AI Foundry](https://learn.microsoft.com/ai-studio) provides a unified platform for developing, testing, and deploying AI applications. The Aspire Azure AI Foundry integration enables you to connect to Azure AI Foundry services from your applications, providing access to various AI capabilities including model deployments, prompt flow, and more.

## Hosting integration

The Aspire Azure AI Foundry hosting integration models the AI Foundry project as the `AzureAIFoundryResource` type. To access this type and APIs for expressing them within your AppHost project, install the [ðŸ“¦ Aspire.Hosting.Azure.AIFoundry](https://www.nuget.org/packages/Aspire.Hosting.Azure.AIFoundry) NuGet package:

<InstallPackage packageName="Aspire.Hosting.Azure.AIFoundry" />

### Add an Azure AI Foundry resource

To add an Azure AI Foundry resource to your AppHost project, call the `AddAzureAIFoundry` method providing a name:

```csharp title="C# â€” AppHost.cs"
var builder = DistributedApplication.CreateBuilder(args);

var aiFoundry = builder.AddAzureAIFoundry("ai-foundry");

builder.AddProject<Projects.ExampleProject>()
       .WithReference(aiFoundry);

// After adding all resources, run the app...
```

The preceding code adds an Azure AI Foundry resource named `ai-foundry` to the AppHost project. The `WithReference` method passes the connection information to the `ExampleProject` project.

### Connect to an existing Azure AI Foundry project

You might have an existing Azure AI Foundry project that you want to connect to. You can chain a call to annotate that your `AzureAIFoundryResource` is an existing resource:

```csharp title="C# â€” AppHost.cs"
var builder = DistributedApplication.CreateBuilder(args);

var existingProjectName = builder.AddParameter("existingProjectName");
var existingProjectResourceGroup = builder.AddParameter("existingProjectResourceGroup");

var aiFoundry = builder.AddAzureAIFoundry("ai-foundry")
                       .AsExisting(existingProjectName, existingProjectResourceGroup);

builder.AddProject<Projects.ExampleProject>()
       .WithReference(aiFoundry);

// After adding all resources, run the app...
```

For more information on treating Azure AI Foundry resources as existing resources, see [Use existing Azure resources](https://learn.microsoft.com/integrations-overview/#use-existing-azure-resources).

## Client integration

To get started with the Aspire Azure AI Foundry client integration, install the [ðŸ“¦ Aspire.Azure.AI.Inference](https://www.nuget.org/packages/Aspire.Azure.AI.Inference) NuGet package in the client-consuming project, that is, the project for the application that uses the Azure AI Foundry client.

<InstallDotNetPackage packageName="Aspire.Azure.AI.Inference" />

### Add an Azure AI Foundry client

In the `Program.cs` file of your client-consuming project, use the `AddAzureChatCompletionsClient` method to register a `ChatCompletionsClient` for dependency injection (DI). The method requires a connection name parameter.

```csharp
builder.AddAzureChatCompletionsClient(connectionName: "ai-foundry");
```

<Aside type="tip">
The `connectionName` parameter must match the name used when adding the Azure AI Foundry resource in the AppHost project. For more information, see Add an Azure AI Foundry resource.
</Aside>

After adding the `ChatCompletionsClient`, you can retrieve the client instance using dependency injection:

```csharp
public class ExampleService(ChatCompletionsClient client)
{
    // Use client...
}
```

For more information, see:

- [Azure.AI.Inference documentation](https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/ai/Azure.AI.Inference/README.md) for examples on using the `ChatCompletionsClient`.
- [Dependency injection in .NET](/dotnet/core/extensions/dependency-injection) for details on dependency injection.

### Add Azure AI Foundry client with registered `IChatClient`

If you're interested in using the `IChatClient` interface with the Azure AI Foundry client, simply chain the `AddChatClient` API to the `AddAzureChatCompletionsClient` method:

```csharp
builder.AddAzureChatCompletionsClient(connectionName: "chat")
       .AddChatClient();
```

For more information on the `IChatClient` and its corresponding library, see [Artificial intelligence in .NET (Preview)](/dotnet/core/extensions/artificial-intelligence).

### Alternative: Use OpenAI client for compatible models

For models that are compatible with the OpenAI API, you can also use the [ðŸ“¦ Aspire.OpenAI](https://www.nuget.org/packages/Aspire.OpenAI) client integration:

```csharp
builder.AddOpenAIClient(connectionName: "chat")
       .AddChatClient();
```

This approach works well with models that support the OpenAI API format.

### Configuration

The Aspire Azure AI Foundry library provides multiple options to configure the Azure AI Foundry connection based on the requirements and conventions of your project. Either an `Endpoint` with `DeploymentId` (using credential-based authentication), or a connection string with an explicit `Key` is required.

#### Use a connection string

When using a connection string from the `ConnectionStrings` configuration section, you can provide the name of the connection string when calling `AddAzureChatCompletionsClient`:

```csharp
builder.AddAzureChatCompletionsClient("chat");
```

The connection string is retrieved from the `ConnectionStrings` configuration section, and there are two supported formats:

##### Azure AI Foundry Endpoint

The recommended approach is to use an Endpoint, which works with the `ChatCompletionsClientSettings.Credential` property to establish a connection. If no credential is configured, the `DefaultAzureCredential` is used.

```json
{
  "ConnectionStrings": {
    "chat": "Endpoint=https://{endpoint}/;DeploymentId={deploymentName}"
  }
}
```

##### Connection string

Alternatively, a custom connection string can be used:

```json
{
  "ConnectionStrings": {
    "chat": "Endpoint=https://{endpoint}/;Key={account_key};DeploymentId={deploymentName}"
  }
}
```

#### Use configuration providers

The Aspire Azure AI Inference library supports `Microsoft.Extensions.Configuration`. It loads the `ChatCompletionsClientSettings` from configuration by using the `Aspire:Azure:AI:Inference` key. Example `appsettings.json` that configures some of the options:

```json
{
  "Aspire": {
    "Azure": {
      "AI": {
        "Inference": {
          "DisableTracing": false,
          "ClientOptions": {
            "UserAgentApplicationId": "myapp"
          }
        }
      }
    }
  }
}
```

For the complete Azure AI Inference client integration JSON schema, see [Aspire.Azure.AI.Inference/ConfigurationSchema.json](https://github.com/dotnet/aspire/blob/main/src/Components/Aspire.Azure.AI.Inference/ConfigurationSchema.json).

#### Use inline delegates

You can pass the `Action<ChatCompletionsClientSettings> configureSettings` delegate to set up some or all the options inline, for example to disable tracing from code:

```csharp
builder.AddAzureChatCompletionsClient(
    "chat",
    static settings => settings.DisableTracing = true);
```

### Observability and telemetry

Aspire integrations automatically set up Logging, Tracing, and Metrics configurations.

#### Logging

The Aspire Azure AI Foundry integration uses the following log categories:

- `Azure`
- `Azure.Core`
- `Azure.Identity`
- `Azure.AI.Inference`

#### Tracing

The Aspire Azure AI Foundry integration emits tracing activities using OpenTelemetry for operations performed with the `ChatCompletionsClient`. The following tracing activities are emitted:

- `Azure.AI.Inference.*`
- `gen_ai.system` (Generic AI system tracing)
- `gen_ai.operation.name` (Operation names for AI calls)

#### Metrics

The Aspire Azure AI Foundry integration currently doesn't support metrics by default due to limitations with the Azure SDK for .NET.
